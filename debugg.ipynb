{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "seed_value = 42\n",
    "random.seed(seed_value)\n",
    "\n",
    "class network:\n",
    "    def __init__(self, layers: np.array):\n",
    "        \n",
    "        '''\n",
    "        Implementing a fully connected neural network.\n",
    "        The network consists of two np.arrays, namely weights and biases.\n",
    "        weights[l] = weights matrix of the l+1-th layer. -->weigths[l][j][i] = w_{ji}_{l+1}\n",
    "        biases[l] = biases of the l+1-th layer. --> biases[l][i] = b^{l+1}_{i}\n",
    "        '''\n",
    "        self.layers = layers\n",
    "        self.weigths = [np.random.rand(layers[i+1], layers[i]) for i in range(len(layers)-1)]\n",
    "        self.biases = [np.random.rand(layers[i],1) for i in range(1, len(layers))]\n",
    "\n",
    "    def forward(self, a : np.array)->np.array:\n",
    "        for i in range(len(self.layers)-1):\n",
    "            a = self.ReLU(np.dot(self.weigths[i], a) + np.transpose(self.biases[i][0])) # numpy will transponse a if necessary, but not b (since we want pointwise addition), added the zeros there since np will return an array of an array\n",
    "        return a\n",
    "    \n",
    "    def SGD(self, train_data: np.array, eta: float, epochs: int, batch_size: int, loss_fn, report: bool = False, validation_data: np.array = None):\n",
    "        '''if report is true, then we need validation data'''\n",
    "        data = train_data\n",
    "\n",
    "        for epoch in tqdm(range(epochs)):\n",
    "            np.random.shuffle(data) # in place\n",
    "            for i in range(0,len(data), batch_size):\n",
    "                self.batch_update(data[i:i+batch_size], eta)\n",
    "\n",
    "            if report:\n",
    "                # might be more interesting to calculate loss and accuracy after each batch update, not after each epoch\n",
    "                loss, accuracy = 0, 0\n",
    "\n",
    "                for (X,y) in validation_data:\n",
    "                    y_pred = self.forward(X)\n",
    "                    loss += loss_fn(y_pred=y_pred, y_true= y)\n",
    "                    # this should be done better\n",
    "                    temp = np.zeros_like(y_pred)\n",
    "                    temp[np.argmax(y_pred)] = 1\n",
    "                    accuracy += np.array_equal(temp, y)\n",
    "\n",
    "                loss /= len(validation_data)\n",
    "                accuracy /= len(validation_data)\n",
    "\n",
    "\n",
    "    def batch_update(self, train_data: np.array, eta: float):\n",
    "        partial_weigths = np.zeros_like(self.weigths)\n",
    "        partial_biases = np.zeros_like(self.biases)\n",
    "\n",
    "        for (X,y) in train_data:\n",
    "            weigths_update, biases_update  = self.backpropagation(X, y)\n",
    "            partial_weigths += weigths_update\n",
    "            partial_biases += biases_update\n",
    "        \n",
    "        partial_weigths /= len(train_data)\n",
    "        partial_biases /= len(train_data)\n",
    "        \n",
    "        self.weigths -= eta * partial_weigths\n",
    "        self.biases -= eta * partial_biases\n",
    "\n",
    "\n",
    "    def backpropagation(self):\n",
    "        pass\n",
    "\n",
    "    def ReLU(self, input: np.array):\n",
    "        return np.maximum(0,input)        \n",
    "\n",
    "    def dReLU(self, input: np.array):\n",
    "        return np.where(input>0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[  1  12   3]\n",
      "  [124   2   1]]\n",
      "\n",
      " [[  1   2   4]\n",
      "  [  5   3   6]]]\n",
      "(2, 2, 3)\n",
      "[[[0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2]]\n",
      "\n",
      " [[0.2 0.2 0.2]\n",
      "  [0.2 0.2 0.2]]]\n"
     ]
    }
   ],
   "source": [
    "test = np.array([[[1, 12, 3], [124, 2, 1]],[[1, 2, 4],[5, 3, 6]]])\n",
    "print(test)\n",
    "print(test.shape)\n",
    "h = np.ones(test.shape)\n",
    "\n",
    "print(h / 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.48582881, 2.85107098])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer = [2,3,2]\n",
    "net = network(layer)\n",
    "net.forward([-1,2])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
