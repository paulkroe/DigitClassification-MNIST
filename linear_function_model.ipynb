{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider y(x) = (5 x, 9 x)\n",
    "want to build a simple model with 1 hidden layer, to test if the model works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[231], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m layers \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([\u001b[39m2\u001b[39m,\u001b[39m2\u001b[39m])\n\u001b[1;32m     17\u001b[0m net \u001b[39m=\u001b[39m network0\u001b[39m.\u001b[39mnetwork(layers\u001b[39m=\u001b[39mlayers, seed_value\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m net\u001b[39m.\u001b[39;49mSGD(train_data\u001b[39m=\u001b[39;49mdata, eta\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, loss_fn\u001b[39m=\u001b[39;49mnetwork0\u001b[39m.\u001b[39;49mmean_square_error, dloss_fn\u001b[39m=\u001b[39;49mnetwork0\u001b[39m.\u001b[39;49mdmean_square_error, seed_value\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m     21\u001b[0m z,a \u001b[39m=\u001b[39m net\u001b[39m.\u001b[39mforward(np\u001b[39m.\u001b[39marray((\u001b[39m6\u001b[39m,\u001b[39m1\u001b[39m)))\n\u001b[1;32m     22\u001b[0m \u001b[39mprint\u001b[39m(z)\n",
      "File \u001b[0;32m~/Documents/3AI/DigitClassification-MNIST/network0.py:48\u001b[0m, in \u001b[0;36mnetwork.SGD\u001b[0;34m(self, train_data, eta, epochs, batch_size, loss_fn, dloss_fn, report, validation_data, seed_value)\u001b[0m\n\u001b[1;32m     46\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mshuffle(data) \u001b[39m# in place\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m,\u001b[39mlen\u001b[39m(data), batch_size):\n\u001b[0;32m---> 48\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_update(data[i:i\u001b[39m+\u001b[39;49mbatch_size], eta, loss_fn\u001b[39m=\u001b[39;49mloss_fn, dloss_fn\u001b[39m=\u001b[39;49mdloss_fn)\n\u001b[1;32m     50\u001b[0m \u001b[39mif\u001b[39;00m report:\n\u001b[1;32m     51\u001b[0m     \u001b[39m# might be more interesting to calculate loss and accuracy after each batch update, not after each epoch\u001b[39;00m\n\u001b[1;32m     52\u001b[0m     loss, accuracy \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/Documents/3AI/DigitClassification-MNIST/network0.py:73\u001b[0m, in \u001b[0;36mnetwork.batch_update\u001b[0;34m(self, train_data, eta, loss_fn, dloss_fn)\u001b[0m\n\u001b[1;32m     70\u001b[0m partial_biases \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39mzeros((\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers[i],\u001b[39m1\u001b[39m)) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayers))]\n\u001b[1;32m     72\u001b[0m \u001b[39mfor\u001b[39;00m (X,y) \u001b[39min\u001b[39;00m train_data:\n\u001b[0;32m---> 73\u001b[0m     weights_update, biases_update  \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbackpropagation(X, y, dloss_fn)\n\u001b[1;32m     75\u001b[0m     partial_weights \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39madd(x,y) \u001b[39mfor\u001b[39;00m (x,y) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(partial_weights, weights_update)]\n\u001b[1;32m     76\u001b[0m     partial_biases \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39madd(x,y) \u001b[39mfor\u001b[39;00m (x,y) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(partial_biases, biases_update)]\n",
      "File \u001b[0;32m~/Documents/3AI/DigitClassification-MNIST/network0.py:110\u001b[0m, in \u001b[0;36mnetwork.backpropagation\u001b[0;34m(self, X, y, dloss_fn)\u001b[0m\n\u001b[1;32m    107\u001b[0m partial_weights\u001b[39m.\u001b[39mreverse()\n\u001b[1;32m    109\u001b[0m deb\u001b[39m.\u001b[39mcheck_biases(\u001b[39mself\u001b[39m, delta)\n\u001b[0;32m--> 110\u001b[0m deb\u001b[39m.\u001b[39;49mcheck_weights(\u001b[39mself\u001b[39;49m, partial_weights)\n\u001b[1;32m    113\u001b[0m \u001b[39mreturn\u001b[39;00m partial_weights, delta\n",
      "File \u001b[0;32m~/Documents/3AI/DigitClassification-MNIST/debugger.py:27\u001b[0m, in \u001b[0;36mcheck_weights\u001b[0;34m(net, test)\u001b[0m\n\u001b[1;32m     25\u001b[0m logger\u001b[39m.\u001b[39mdebug(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mweights check: test shape at index \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mtest[i]\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m | weights shape at index \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m}\u001b[39;00m\u001b[39m: \u001b[39m\u001b[39m{\u001b[39;00mnet\u001b[39m.\u001b[39mweights[i]\u001b[39m.\u001b[39mshape\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     26\u001b[0m logger\u001b[39m.\u001b[39mwarn(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtest: \u001b[39m\u001b[39m{\u001b[39;00mtest\u001b[39m}\u001b[39;00m\u001b[39m | weights: \u001b[39m\u001b[39m{\u001b[39;00mnet\u001b[39m.\u001b[39mweights\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m \u001b[39massert\u001b[39;00m(\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "import network0\n",
    "import numpy as np\n",
    "import random\n",
    "importlib.reload(network0)\n",
    "#create data\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "def fill():\n",
    "    x = random.random()\n",
    "    return [np.array((x,x)), np.array((x,0))]\n",
    "\n",
    "data = [fill() for x in range(0,100)]\n",
    "\n",
    "layers = np.array([2,2])\n",
    "net = network0.network(layers=layers, seed_value=42)\n",
    "net.SGD(train_data=data, eta=0.1, epochs=1, batch_size=10, loss_fn=network0.mean_square_error, dloss_fn=network0.dmean_square_error, seed_value=10)\n",
    "\n",
    "\n",
    "z,a = net.forward(np.array((6,1)))\n",
    "print(z)\n",
    "print(a)\n",
    "print(net.biases)\n",
    "print(net.weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, array([[2.97923465],\n",
      "       [6.43627978]])]\n"
     ]
    }
   ],
   "source": [
    "import network0\n",
    "importlib.reload(network0)\n",
    "\n",
    "layers=np.array([1,2])\n",
    "test = network0.network(layers=layers, seed_value=42)\n",
    "\n",
    "a,b = test.forward(6)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76324059, 0.87809664, 0.41750914, 0.60557756])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.rand(4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
